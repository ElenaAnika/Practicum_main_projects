# Прогнозирование оттока клиентов провайдера

Оператор связи  хочет научиться прогнозировать отток клиентов. Если выяснится, что пользователь планирует уйти, ему будут предложены промокоды и специальные условия. Команда оператора собрала персональные данные о некоторых клиентах, информацию об их тарифах и договорах.


**Цель проекта**

Максимизируем AUC-ROC, целевой показатель - 0,85.
Метрика выбрана, исходя из бизнес-задачи: минимизировать возможные убытки от ухода. Это можно достигнуть при следующем условии: сбалансировать ошибку по некорректному определению тех, кто ушел (False Positive) и тех, кто реально ушел, но мы их не предсказали (False Negative). Клиенты, неправильно размеченные как готовые уйти, "незаслуженно" получат скидку, а клиенты, которых мы не разметили, как готовых разорвать контракт, уйдут и компания долгосрочно потеряет клиента.

**Итог**:
Итак, мы достигли поставленной цели: **получили метрику roc-auc в 0.91** на тестовой выборке для определения потенциально уходящих клиентов, т.е. добились вероятности в 91% факта определения случайно выбранного ушедшего клиента как ушедшего. Совместно с accuracy в 83% это позволит предсказать потенциально уходящих клиентов провайдера и предложить им промо-код. "Пропущенных" моделью ушедших клиентов немного, около 5% (86 из 1761 на тесте), еще 12% (220 из 1761) проранжированы ошибочно как ушедшие. Последние могут "зря" получить промокод, даже если они не собирались уходить, однако в долгосрочной перспективе это может увеличить их лояльность (требует отдельного исследования после внедрения модели). **Общее потенциальное сокращение убытков бизнеса составялет 66% в результате применения данной модели.**

Ручной анализ признаков до загрузки в модель показал, что часть параметров одинаково характерна как для лояльных клиентов, так и для ушедших (например, пользование стриминговыми сервисами ТВ и кино), впоследствии большинство выводов по таким признакам подтвердились после первичного обучения модели и выгрузки из нее feature_impotance. Удаление таких признаков ("шума" для модели) позволило повысить качество предсказаний. Дополнительно были сгенерированы признаки времени сотрудничества и среднемесячного чека.

Использованные библиотеки:
- joblib
- lightgbm
- matplotlib.
- numpy
- pandas
- sklearn
- scipy
- seaborn
- catboost
- imblearn
- sklearn


## Использованные параметры финальной модели.

Выборка была разделена в пропорции 75%/25%, random_state зафиксирован на уровне 130223.\
Были проверены модели Logistic_regression, RandomForest, CatBoost, LGBM.

На тестовой выборке была использована модель LGBM со следующими гиперпараметрами:
 - class_weight='balanced',
 - max_depth=12,
 - n_estimators=90.
 
  
 Небольшое количество деревьев обусловлено небольшим датасетом, при увеличении количества деревьев качество модели падало.
 
При подготовке были удалены "шумные" признаки, сохранены следующие:
- 'Type',
- 'PaperlessBilling',
- 'gender',
- 'InternetService',
- 'OnlineBackup',
- 'TechSupport',
- 'StreamingTV',
- 'AVG_coop',
- 'AVG_check'

Итогом стал результат на тренировочной выборке roc-auc 0.888, на тестовой результат улучшен до 0.91.